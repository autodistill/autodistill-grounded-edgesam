Metadata-Version: 2.1
Name: autodistill-grounded-edgesam
Version: 0.1.0
Summary: Model for use with Autodistill
Home-page: https://github.com/autodistill/autodistill-segment-anything
Author: Roboflow
Author-email: support@roboflow.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Requires-Dist: autodistill
Requires-Dist: numpy>=1.20.0
Requires-Dist: opencv-python>=4.6.0
Requires-Dist: rf_groundingdino
Requires-Dist: rf_segment_anything
Requires-Dist: supervision
Provides-Extra: dev
Requires-Dist: flake8; extra == "dev"
Requires-Dist: black==22.3.0; extra == "dev"
Requires-Dist: isort; extra == "dev"
Requires-Dist: twine; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: wheel; extra == "dev"

**‚ö†Ô∏è This is an example README for use in creating a Base Model. You will need to adjust this document for the model you are using.**

<div align="center">
  <p>
    <a align="center" href="" target="_blank">
      <img
        width="850"
        src="https://media.roboflow.com/open-source/autodistill/autodistill-banner.png"
      >
    </a>
  </p>
</div>

# Autodistill Grounded EdgeSAM Module

This repository contains the code supporting the Grounded EdgeSAM base model for use with [Autodistill](https://github.com/autodistill/autodistill).

[EdgeSAM](https://github.com/chongzhou96/EdgeSAM), introduced in the "EdgeSAM: Prompt-In-the-Loop Distillation for On-Device Deployment of SAM" paper, is a faster version of the Segment Anything model.

Grounded EdgeSAM combines [Grounding DINO](https://blog.roboflow.com/grounding-dino-zero-shot-object-detection/) and EdgeSAM, allowing you to identify objects and generate segmentation masks for them.

Read the full [Autodistill documentation](https://autodistill.github.io/autodistill/) to learn more about Autodistill.

## Installation

To use Grounded EdgeSAM with autodistill, you need to install the following dependency:

```bash
pip3 install autodistill-grounded-edgesam
```

## Quickstart

```python
from autodistill_clip import CLIP

# define an ontology to map class names to our GroundingDINO prompt
# the ontology dictionary has the format {caption: class}
# where caption is the prompt sent to the base model, and class is the label that will
# be saved for that caption in the generated annotations
# then, load the model
from autodistill_grounded_edgesam import GroundedEdgeSAM
from autodistill.detection import CaptionOntology
from autodistill.utils import plot
import cv2

# define an ontology to map class names to our GroundedSAM prompt
# the ontology dictionary has the format {caption: class}
# where caption is the prompt sent to the base model, and class is the label that will
# be saved for that caption in the generated annotations
# then, load the model
base_model = GroundedEdgeSAM(
    ontology=CaptionOntology(
        {
            "person": "person",
            "forklift": "forklift",
        }
    )
)

# run inference on a single image
results = base_model.predict("logistics.jpeg")

plot(
    image=cv2.imread("logistics.jpeg"),
    classes=base_model.ontology.classes(),
    detections=results
)

# label a folder of images
base_model.label("./context_images", extension=".jpeg")
```

## License

This repository is released under an [S-Lab License 1.0](LICENSE) license.

## üèÜ Contributing

We love your input! Please see the core Autodistill [contributing guide](https://github.com/autodistill/autodistill/blob/main/CONTRIBUTING.md) to get started. Thank you üôè to all our contributors!
